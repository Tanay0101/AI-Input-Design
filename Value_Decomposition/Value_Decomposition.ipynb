{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from Environment import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "dense_1_user =  Dense(32, activation = 'relu')\n",
    "dense_2_user =  Dense(32, activation = 'relu')\n",
    "# dense_3_user =  Dense(32, activation = 'relu')\n",
    "\n",
    "dense_1_assist =  Dense(32, activation = 'relu')\n",
    "lstm_1_assist = LSTM(32, activation = 'relu')\n",
    "# dense_2_assist = Dense(32, activation = 'relu')\n",
    "\n",
    "advantage_layer_user = Dense(4)\n",
    "value_layer_user = Dense(1)\n",
    "\n",
    "advantage_layer_assist = Dense(4)\n",
    "value_layer_assist = Dense(1)\n",
    "\n",
    "# advantage_layer = Dense(4)\n",
    "# value_layer = Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Design:\n",
    "    def __init__(self, steps = 4):        \n",
    "        self.loss_fn = tf.keras.losses.mean_squared_error\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "        self.batch_size = 128\n",
    "        self.replay_buffer_size = 1024\n",
    "        self.replay_buffer = Replay_Buffer(self.replay_buffer_size)\n",
    "        self.epsilon = 1\n",
    "        self.gamma = 0.9\n",
    "        self.env = Environment()\n",
    "        self.env.cells = np.array([[0.7, 0.1], [0.1, 0.1], [0.5, 0.7], [0.6, 0.2], [0.7, 0.4], [0.2, 0.9]])\n",
    "        \n",
    "        #-------------------------------------------------------------------------------------------------\n",
    "        input_A = Input(shape = (4,))\n",
    "        input_B = Input(shape = (steps,6))\n",
    "        action_user = Input(shape = 1, dtype = tf.int32)\n",
    "        action_assist = Input(shape = 1, dtype = tf.int32)\n",
    "        \n",
    "        x = Subtract()([input_A[:, 2:], input_A[:, :2]])\n",
    "        x = dense_1_user(x)\n",
    "        x = dense_2_user(x)\n",
    "#         x = dense_3_user(x)\n",
    "        adv_user = advantage_layer_user(x)\n",
    "        val_user = value_layer_user(x)\n",
    "        output_user = adv_user - tf.reduce_mean(adv_user, axis = 1, keepdims = True) + val_user\n",
    "        \n",
    "        self.user_model = Model(inputs = input_A, outputs = output_user)\n",
    "        self.user_model.summary()\n",
    "        \n",
    "        self.target_user_model = tf.keras.models.clone_model(self.user_model)\n",
    "        self.target_user_model.set_weights(self.user_model.get_weights())\n",
    "        \n",
    "\n",
    "        \n",
    "        y = dense_1_assist(input_B)\n",
    "        y = lstm_1_assist(y)\n",
    "#         y = dense_2_assist(y)\n",
    "        adv_assist = advantage_layer_assist(y)\n",
    "        val_assist = value_layer_assist(y)\n",
    "        output_assist = adv_assist - tf.reduce_mean(adv_assist, axis = 1, keepdims = True) + val_assist\n",
    "        \n",
    "        self.assist_model = Model(inputs = input_B, outputs = output_assist)\n",
    "        self.assist_model.summary()\n",
    "        \n",
    "        self.target_assist_model = tf.keras.models.clone_model(self.assist_model)\n",
    "        self.target_assist_model.set_weights(self.assist_model.get_weights())\n",
    "        \n",
    "        mask_user = tf.reduce_sum(tf.one_hot(action_user, 4), axis = 1)\n",
    "        mask_assist = tf.reduce_sum(tf.one_hot(action_assist, 4), axis = 1)\n",
    "        output_user = output_user*mask_user\n",
    "        output_assist = output_assist*mask_assist\n",
    "        \n",
    "        out = tf.reduce_sum(output_user + output_assist, axis = 1, keepdims = True)\n",
    "        \n",
    "        self.model = Model(inputs = [input_A, input_B, action_user, action_assist], outputs = out)  \n",
    "        self.model.summary() \n",
    "        #-------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def infer(self):\n",
    "        ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist,\\\n",
    "        reward_assist, next_ob_assist, done = self.sample_exp()\n",
    "        \n",
    "        ob_user = ob_user[1:4]\n",
    "        action_user = action_user[1:4]\n",
    "        reward_user = reward_user[1:4]\n",
    "        \n",
    "        ob_assist = ob_assist[1:4]\n",
    "        action_assist = action_assist[1:4]\n",
    "        reward_assist = reward_assist[1:4]\n",
    "        \n",
    "        print(action_user, action_assist)\n",
    "        \n",
    "        print(self.user_model(ob_user))\n",
    "        print(self.assist_model(ob_assist))\n",
    "        \n",
    "        print(self.model([ob_user, ob_assist, action_user, action_assist]))\n",
    "    \n",
    "    def exp_policy_user(self, state):\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            return np.random.randint(4)\n",
    "        else:\n",
    "            state = np.array(state)[np.newaxis]\n",
    "            Q_values = self.user_model(state)\n",
    "            return np.argmax(Q_values[0])\n",
    "    \n",
    "    def exp_policy_assist(self, state):\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            return np.random.randint(1,5)\n",
    "        else:\n",
    "            state = np.array(state)[np.newaxis]\n",
    "            Q_values = self.assist_model(state)\n",
    "            return np.argmax(Q_values[0])+1\n",
    "    \n",
    "    def step(self, ob_user, prev_steps_assist):\n",
    "        curr_loc = ob_user[:2]\n",
    "        target_loc = ob_user[2:4]\n",
    "        \n",
    "        action_user = self.exp_policy_user(ob_user)\n",
    "        action_user_one_hot = make_one_hot(action_user, 4)\n",
    "        \n",
    "        ob_assist = [action_user_one_hot + ob_user[:2]]\n",
    "        ob_assist = prev_steps_assist + ob_assist \n",
    "        action_assist = self.exp_policy_assist(ob_assist)\n",
    "        \n",
    "        new_loc, reward_user, reward_assist, done = self.env.step(action_user, action_assist-1, target_loc, curr_loc)\n",
    "        \n",
    "        next_ob_user = new_loc[:]\n",
    "        next_ob_user = next_ob_user + target_loc\n",
    "        \n",
    "        next_action_user = self.exp_policy_user(next_ob_user)\n",
    "        next_action_user_one_hot = make_one_hot(next_action_user, 4)\n",
    "        next_ob_assist = [next_action_user_one_hot + next_ob_user[:2]]\n",
    "        next_ob_assist = ob_assist[1:] + next_ob_assist\n",
    "        \n",
    "        self.add_replay_buffer(ob_user, action_user, reward_user, next_ob_user, ob_assist,\\\n",
    "                          action_assist-1, reward_assist, next_ob_assist, done)\n",
    "        \n",
    "        return next_ob_user, ob_assist[1:], reward_user, reward_assist, done \n",
    "        \n",
    "        \n",
    "    \n",
    "    def add_replay_buffer(self, ob_user, action_user, reward_user, next_ob_user, ob_assist,\\\n",
    "                         action_assist, reward_assist, next_ob_assist, done):\n",
    "        \n",
    "        self.replay_buffer.ob_user_history.append(ob_user)\n",
    "        self.replay_buffer.action_user_history.append(action_user)\n",
    "        self.replay_buffer.reward_user_history.append(reward_user)\n",
    "        self.replay_buffer.next_ob_user_history.append(next_ob_user)\n",
    "        self.replay_buffer.ob_assist_history.append(ob_assist)\n",
    "        self.replay_buffer.action_assist_history.append(action_assist)\n",
    "        self.replay_buffer.reward_assist_history.append(reward_assist)\n",
    "        self.replay_buffer.next_ob_assist_history.append(next_ob_assist)\n",
    "        self.replay_buffer.done_history.append(done)\n",
    "    \n",
    "    def sample_exp(self):\n",
    "        indices = np.random.randint(len(self.replay_buffer.done_history), size = self.batch_size)\n",
    "        \n",
    "        ob_user = np.array([self.replay_buffer.ob_user_history[i] for i in indices])\n",
    "        action_user = np.array([self.replay_buffer.action_user_history[i] for i in indices])\n",
    "        reward_user = np.array([self.replay_buffer.reward_user_history[i] for i in indices])\n",
    "        next_ob_user = np.array([self.replay_buffer.next_ob_user_history[i] for i in indices])\n",
    "        ob_assist = np.array([self.replay_buffer.ob_assist_history[i] for i in indices])\n",
    "        action_assist = np.array([self.replay_buffer.action_assist_history[i] for i in indices])\n",
    "        reward_assist = np.array([self.replay_buffer.reward_assist_history[i] for i in indices])\n",
    "        next_ob_assist = np.array([self.replay_buffer.next_ob_assist_history[i] for i in indices])\n",
    "        done = np.array([self.replay_buffer.done_history[i] for i in indices])\n",
    "        \n",
    "        return ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist, reward_assist, next_ob_assist, done \n",
    "    \n",
    "    def train(self):\n",
    "        ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist,\\\n",
    "        reward_assist, next_ob_assist, done = self.sample_exp()\n",
    "        \n",
    "        input_A = ob_user\n",
    "        input_B = ob_assist\n",
    "        \n",
    "        rewards = reward_user + reward_assist\n",
    "        \n",
    "        next_Q_values_user, next_Q_values_assist = self.user_model(next_ob_user), self.assist_model(next_ob_assist)\n",
    "        best_next_actions_user, best_next_actions_assist = tf.math.argmax(next_Q_values_user, axis = 1), tf.math.argmax(next_Q_values_assist, axis = 1)\n",
    "        next_Q_values_user, next_Q_values_assist = self.target_user_model(next_ob_user), self.target_assist_model(next_ob_assist)\n",
    "        \n",
    "        best_next_Q_values_user = tf.reduce_sum(next_Q_values_user*tf.one_hot(best_next_actions_user, 4), axis = 1)\n",
    "        best_next_Q_values_assist = tf.reduce_sum(next_Q_values_user*tf.one_hot(best_next_actions_assist, 4), axis = 1)\n",
    "        best_next_Q_values = best_next_Q_values_user + best_next_Q_values_assist\n",
    "        \n",
    "        target_Q_values = rewards + (1-done)*self.gamma*best_next_Q_values\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            Q_values = self.model([input_A, input_B, action_user, action_assist])\n",
    "            loss = tf.reduce_mean(self.loss_fn(target_Q_values, Q_values))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        \n",
    "        Q_values_assist = self.assist_model(input_B)\n",
    "        with tf.GradientTape() as tape:\n",
    "            Q_values_user = self.user_model(input_A)\n",
    "            loss = tf.reduce_mean(self.loss_fn(Q_values_assist, Q_values_user))\n",
    "            \n",
    "        grads = tape.gradient(loss, self.user_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.user_model.trainable_variables))\n",
    "            \n",
    "        with tf.GradientTape() as tape:\n",
    "            Q_values_assist = self.assist_model(input_B)\n",
    "            loss = tf.reduce_mean(self.loss_fn(Q_values_assist, Q_values_user))\n",
    "            \n",
    "        grads = tape.gradient(loss, self.assist_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.assist_model.trainable_variables))                          \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icon Locations:\n",
      "[[0.4 0.2]\n",
      " [0.8 0. ]\n",
      " [0.9 0.7]\n",
      " [0.  0.1]\n",
      " [0.  0.5]\n",
      " [0.4 0.2]]\n",
      "Icon usage Probabilities\n",
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2)            0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           96          subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1)]          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 4)]          0           dense_3[0][0]                    \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 4)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,317\n",
      "Trainable params: 1,317\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4, 32)        224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            132         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 1)]          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 4)]          0           dense_5[0][0]                    \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 4)]          0           tf_op_layer_Sub_1[0][0]          \n",
      "                                                                 dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,709\n",
      "Trainable params: 8,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2)            0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           96          subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4, 32)        224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            132         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1)]          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 1)]          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 4)]          0           dense_3[0][0]                    \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_OneHot (TensorFlowO [(None, 1, 4)]       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 4)]          0           dense_5[0][0]                    \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_OneHot_1 (TensorFlo [(None, 1, 4)]       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 4)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_OneHot[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 4)]          0           tf_op_layer_Sub_1[0][0]          \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 4)]          0           tf_op_layer_OneHot_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 4)]          0           tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 4)]          0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 1)]          0           tf_op_layer_AddV2_2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 10,026\n",
      "Trainable params: 10,026\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "steps = 4\n",
    "model = AI_Design(steps)\n",
    "env = model.env\n",
    "\n",
    "\n",
    "if os.path.exists('user_model.h5'):\n",
    "    model.user_model = tf.keras.load_model('user_model.h5')\n",
    "    model.assist_model = tf.keras.load_model('assist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_prev_steps(prev_steps_assist, steps):\n",
    "    prev_steps_assist = [[0,0,0,0,-1,-1] for i in range(steps-1)]\n",
    "    return prev_steps_assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 101/100000 [00:59<16:57:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                         | 301/100000 [02:58<18:31:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                                                         | 501/100000 [05:02<19:07:47,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.321940632959965\n",
      "Successful runs = 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                         | 667/100000 [06:46<16:48:26,  1.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e5007ce31455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mob_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_steps_assist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_assist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_steps_assist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mepisode_reward\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mreward_user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-657db9f7524c>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, ob_user, prev_steps_assist)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mnext_ob_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_ob_user\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtarget_loc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mnext_action_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_policy_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_ob_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mnext_action_user_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_action_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mnext_ob_assist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext_action_user_one_hot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnext_ob_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-657db9f7524c>\u001b[0m in \u001b[0;36mexp_policy_user\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mQ_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3096\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3098\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_defun_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3099\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = 40\n",
    "reached = 0\n",
    "reached_history = []\n",
    "max_reached = 0\n",
    "\n",
    "running_reward = 0\n",
    "\n",
    "for epoch in tqdm(range(100000)):\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    start, dest = env.give_start_dest()\n",
    "    ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "    prev_steps_assist = []\n",
    "    prev_steps_assist = give_prev_steps(prev_steps_assist, steps)\n",
    "    step = 0\n",
    "    \n",
    "    while not done and step<max_steps:\n",
    "        ob_user, prev_steps_assist, reward_user, reward_assist, done = model.step(ob_user, prev_steps_assist)\n",
    "        episode_reward+=reward_user\n",
    "        step+=1\n",
    "        if done:\n",
    "            reached+=1\n",
    "    \n",
    "    if epoch:\n",
    "        running_reward = 0.01 * episode_reward + (1 - 0.01) * running_reward\n",
    "    else:\n",
    "        running_reward = episode_reward\n",
    "        \n",
    "    if epoch>50:\n",
    "        model.train()\n",
    "        \n",
    "        if epoch%100==0:\n",
    "            model.target_user_model.set_weights(model.user_model.get_weights())\n",
    "            model.target_assist_model.set_weights(model.assist_model.get_weights())\n",
    "            reached_history.append(reached)\n",
    "            rewards = []\n",
    "            \n",
    "            if reached>max_reached:\n",
    "                print(reached)\n",
    "                print('Saved Weights')\n",
    "                max_reached = reached\n",
    "                model.user_model.save('user_model.h5')\n",
    "                model.assist_model.save('assist_model.h5')\n",
    "                \n",
    "            reached = 0\n",
    "            \n",
    "            if epoch%500==0:\n",
    "                print(f'Running reward = {running_reward}')\n",
    "                print(f'Successful runs = {np.mean(reached_history)}')\n",
    "                reached_history = []\n",
    "                \n",
    "                if epoch%1000==0:\n",
    "                    model.epsilon-=0.01\n",
    "                    model.epsilon= max(model.epsilon, 0.1)\n",
    "                    \n",
    "                    if epoch%20000==0:\n",
    "                        model.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2] [1 0 2]\n",
      "tf.Tensor(\n",
      "[[-6.131412  -6.121198  -6.099323  -6.111665 ]\n",
      " [-6.1962185 -6.247878  -6.2020316 -6.215896 ]\n",
      " [-6.2751927 -6.254424  -6.1690855 -6.229144 ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-6.2527876 -6.224664  -6.2342153 -6.2371244]\n",
      " [-6.2592874 -6.2551684 -6.289589  -6.256006 ]\n",
      " [-6.2622766 -6.297505  -6.1454015 -6.323362 ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-12.3363285]\n",
      " [-12.4751835]\n",
      " [-12.314487 ]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
