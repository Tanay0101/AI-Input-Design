{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from Environment import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1_user =  Dense(32, activation = 'relu')\n",
    "dense_2_user =  Dense(32, activation = 'relu')\n",
    "# dense_3_user =  Dense(32, activation = 'relu')\n",
    "\n",
    "dense_1_assist =  Dense(32, activation = 'relu')\n",
    "lstm_1_assist = LSTM(32, activation = 'tanh')\n",
    "dense_2_assist = Dense(32, activation = 'relu')\n",
    "\n",
    "advantage_layer_user = Dense(4)\n",
    "value_layer_user = Dense(1)\n",
    "\n",
    "advantage_layer_assist = Dense(4)\n",
    "value_layer_assist = Dense(1)\n",
    "\n",
    "# advantage_layer = Dense(4)\n",
    "# value_layer = Dense(1)\n",
    "\n",
    "# advantage_layer_user = advantage_layer\n",
    "# advantage_layer_assist = advantage_layer\n",
    "\n",
    "# value_layer_user = value_layer\n",
    "# value_layer_assist = value_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Design:\n",
    "    def __init__(self, steps = 4):        \n",
    "        self.loss_fn = tf.keras.losses.mean_squared_error\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "        self.batch_size = 128\n",
    "        self.replay_buffer_size = 1024\n",
    "        self.replay_buffer = Replay_Buffer(self.replay_buffer_size)\n",
    "        self.epsilon = 1\n",
    "        self.gamma = 0.9\n",
    "        self.env = Environment()\n",
    "        self.env.cells = np.array([[0.7, 0.1], [0.1, 0.1], [0.5, 0.7], [0.6, 0.2], [0.7, 0.4], [0.2, 0.9]])\n",
    "#         self.env_cells = np.array([[0.7, 0.1]])\n",
    "        self.env_cell_mapping = give_mapping(self.env.cells)\n",
    "        self.env_cell_mapping = self.env_cell_mapping[np.newaxis, :, :, np.newaxis]\n",
    "        #-------------------------------------------------------------------------------------------------\n",
    "        input_A = Input(shape = (4,))\n",
    "        input_B = Input(shape = (steps,6))\n",
    "        input_C = Input(shape = (11, 11, 1)) #Location of every icon\n",
    "                 \n",
    "        action_user = Input(shape = 1, dtype = tf.int32)\n",
    "        action_assist = Input(shape = 1, dtype = tf.int32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #User Network \n",
    "        \n",
    "        \n",
    "        x = Subtract()([input_A[:, 2:], input_A[:, :2]])\n",
    "        x = dense_1_user(x)\n",
    "        x = dense_2_user(x)\n",
    "#         x = dense_3_user(x)\n",
    "        adv_user = advantage_layer_user(x)\n",
    "        val_user = value_layer_user(x)\n",
    "        output_user = adv_user - tf.reduce_mean(adv_user, axis = 1, keepdims = True) + val_user\n",
    "        \n",
    "        self.user_model = Model(inputs = input_A, outputs = output_user)\n",
    "        self.user_model.summary()\n",
    "        \n",
    "        self.target_user_model = tf.keras.models.clone_model(self.user_model)\n",
    "        self.target_user_model.set_weights(self.user_model.get_weights())\n",
    "        \n",
    "\n",
    "        \n",
    "        #Assistant Network\n",
    "        z = tf.keras.layers.Conv2D(filters = 2, kernel_size = 3, activation = 'relu')(input_C)\n",
    "        z = tf.keras.layers.MaxPooling2D()(z)\n",
    "        z = tf.keras.layers.Flatten()(z)\n",
    "        z = tf.keras.layers.Dense(32, activation = 'relu')(z)\n",
    "        \n",
    "        y = dense_1_assist(input_B)\n",
    "        y = lstm_1_assist(y)\n",
    "        y = tf.keras.layers.Concatenate()([y,z])\n",
    "        y = dense_2_assist(y)\n",
    "        adv_assist = advantage_layer_assist(y)\n",
    "        val_assist = value_layer_assist(y)\n",
    "        output_assist = adv_assist - tf.reduce_mean(adv_assist, axis = 1, keepdims = True) + val_assist\n",
    "        \n",
    "        self.assist_model = Model(inputs = [input_B, input_C], outputs = output_assist)\n",
    "        self.assist_model.summary()\n",
    "        \n",
    "        self.target_assist_model = tf.keras.models.clone_model(self.assist_model)\n",
    "        self.target_assist_model.set_weights(self.assist_model.get_weights())\n",
    "        \n",
    "        \n",
    "        #Complete Network\n",
    "\n",
    "        mask_user = tf.reduce_sum(tf.one_hot(action_user, 4), axis = 1)\n",
    "        mask_assist = tf.reduce_sum(tf.one_hot(action_assist, 4), axis = 1)\n",
    "        output_user = output_user*mask_user\n",
    "        output_assist = output_assist*mask_assist\n",
    "        \n",
    "        out = tf.reduce_sum(output_user + output_assist, axis = 1, keepdims = True)\n",
    "        \n",
    "        self.model = Model(inputs = [input_A, input_B, input_C, action_user, action_assist], outputs = out)  \n",
    "        self.model.summary() \n",
    "        #-------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def infer(self):\n",
    "        ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist,\\\n",
    "        reward_assist, next_ob_assist, done, importance, indices = self.sample_exp()\n",
    "        \n",
    "        ob_user = ob_user[:4]\n",
    "        action_user = action_user[:4]\n",
    "        reward_user = reward_user[:4]\n",
    "        \n",
    "        ob_assist = ob_assist[:4]\n",
    "        action_assist = action_assist[:4]\n",
    "        reward_assist = reward_assist[:4]\n",
    "        \n",
    "        print(action_user, action_assist)\n",
    "        \n",
    "        print(self.user_model(ob_user))\n",
    "        print(self.assist_model([ob_assist, np.vstack(tuple([self.env_cell_mapping]*4))]))\n",
    "        \n",
    "        print(self.model([ob_user, ob_assist, np.vstack(tuple([self.env_cell_mapping]*4)), action_user, action_assist]))\n",
    "    \n",
    "    def exp_policy_user(self, state, next_action = False):\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            return np.random.randint(4)\n",
    "        else:\n",
    "            state = np.array(state)[np.newaxis]\n",
    "            if next_action == False:\n",
    "                Q_values = self.user_model(state)\n",
    "            else:\n",
    "                Q_values = self.target_user_model(state)\n",
    "            return np.argmax(Q_values[0])\n",
    "    \n",
    "    def exp_policy_assist(self, state):\n",
    "        if np.random.rand()<self.epsilon:\n",
    "            return np.random.randint(1,5)\n",
    "        else:\n",
    "            state = np.array(state)[np.newaxis]\n",
    "            Q_values = self.assist_model([state, self.env_cell_mapping])\n",
    "            return np.argmax(Q_values[0])+1\n",
    "    \n",
    "    def step(self, ob_user, prev_steps_assist):\n",
    "        curr_loc = ob_user[:2]\n",
    "        target_loc = ob_user[2:4]\n",
    "        \n",
    "        action_user = self.exp_policy_user(ob_user)\n",
    "        action_user_one_hot = make_one_hot(action_user, 4)\n",
    "        \n",
    "        ob_assist = [action_user_one_hot + ob_user[:2]]\n",
    "        ob_assist = prev_steps_assist + ob_assist \n",
    "        action_assist = self.exp_policy_assist(ob_assist)\n",
    "        \n",
    "        new_loc, reward_user, reward_assist, done = self.env.step(action_user, action_assist-1, target_loc, curr_loc)\n",
    "        \n",
    "        next_ob_user = new_loc[:]\n",
    "        next_ob_user = next_ob_user + target_loc\n",
    "        \n",
    "        next_action_user = self.exp_policy_user(next_ob_user, next_action = True)\n",
    "        next_action_user_one_hot = make_one_hot(next_action_user, 4)\n",
    "        next_ob_assist = [next_action_user_one_hot + next_ob_user[:2]]\n",
    "        next_ob_assist = ob_assist[1:] + next_ob_assist\n",
    "        \n",
    "        self.add_replay_buffer(ob_user, action_user, reward_user, next_ob_user, ob_assist,\\\n",
    "                          action_assist-1, reward_assist, next_ob_assist, done)\n",
    "        \n",
    "        return next_ob_user, ob_assist[1:], reward_user, reward_assist, done \n",
    "        \n",
    "        \n",
    "    \n",
    "    def add_replay_buffer(self, ob_user, action_user, reward_user, next_ob_user, ob_assist,\\\n",
    "                         action_assist, reward_assist, next_ob_assist, done):\n",
    "        \n",
    "        self.replay_buffer.ob_user_history.append(ob_user)\n",
    "        self.replay_buffer.action_user_history.append(action_user)\n",
    "        self.replay_buffer.reward_user_history.append(reward_user)\n",
    "        self.replay_buffer.next_ob_user_history.append(next_ob_user)\n",
    "        self.replay_buffer.ob_assist_history.append(ob_assist)\n",
    "        self.replay_buffer.action_assist_history.append(action_assist)\n",
    "        self.replay_buffer.reward_assist_history.append(reward_assist)\n",
    "        self.replay_buffer.next_ob_assist_history.append(next_ob_assist)\n",
    "        self.replay_buffer.done_history.append(done)\n",
    "        self.replay_buffer.priorities.append(self.replay_buffer.max_val)\n",
    "    \n",
    "    def sample_exp(self):\n",
    "        sample_probs = self.replay_buffer.get_probabilities(priority_scale = 0.7)\n",
    "        indices = np.random.choice(len(self.replay_buffer.done_history), size = self.batch_size, p = sample_probs)\n",
    "        importance = self.replay_buffer.get_importance(sample_probs[indices])\n",
    "        \n",
    "        ob_user = np.array([self.replay_buffer.ob_user_history[i] for i in indices])\n",
    "        action_user = np.array([self.replay_buffer.action_user_history[i] for i in indices])\n",
    "        reward_user = np.array([self.replay_buffer.reward_user_history[i] for i in indices])\n",
    "        next_ob_user = np.array([self.replay_buffer.next_ob_user_history[i] for i in indices])\n",
    "        ob_assist = np.array([self.replay_buffer.ob_assist_history[i] for i in indices])\n",
    "        action_assist = np.array([self.replay_buffer.action_assist_history[i] for i in indices])\n",
    "        reward_assist = np.array([self.replay_buffer.reward_assist_history[i] for i in indices])\n",
    "        next_ob_assist = np.array([self.replay_buffer.next_ob_assist_history[i] for i in indices])\n",
    "        done = np.array([self.replay_buffer.done_history[i] for i in indices])\n",
    "        \n",
    "        return ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist, reward_assist, next_ob_assist, done,\\\n",
    "    importance, indices \n",
    "    \n",
    "    def train(self):\n",
    "        ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist,\\\n",
    "        reward_assist, next_ob_assist, done, importance, indices = self.sample_exp()\n",
    "        \n",
    "        input_A = ob_user\n",
    "        input_B = ob_assist\n",
    "        input_C = np.vstack(tuple([self.env_cell_mapping]*128))\n",
    "        \n",
    "        rewards = reward_user + reward_assist\n",
    "        \n",
    "        next_Q_values_user, next_Q_values_assist = self.user_model(next_ob_user), self.assist_model([next_ob_assist, input_C])\n",
    "        best_next_actions_user, best_next_actions_assist = tf.math.argmax(next_Q_values_user, axis = 1), tf.math.argmax(next_Q_values_assist, axis = 1)\n",
    "        next_Q_values_user, next_Q_values_assist = self.target_user_model(next_ob_user), self.target_assist_model([next_ob_assist, input_C])\n",
    "        \n",
    "        best_next_Q_values_user = tf.reduce_sum(next_Q_values_user*tf.one_hot(best_next_actions_user, 4), axis = 1)\n",
    "        best_next_Q_values_assist = tf.reduce_sum(next_Q_values_user*tf.one_hot(best_next_actions_assist, 4), axis = 1)\n",
    "        best_next_Q_values = best_next_Q_values_user + best_next_Q_values_assist\n",
    "        \n",
    "        target_Q_values = rewards + (1-done)*self.gamma*best_next_Q_values\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            Q_values = self.model([input_A, input_B, input_C, action_user, action_assist])\n",
    "            error = tf.multiply(self.loss_fn(target_Q_values, Q_values), importance**(1-self.epsilon))\n",
    "            loss = tf.reduce_mean(error)\n",
    "        \n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        self.replay_buffer.set_priorities(indices, error)\n",
    "        \n",
    "        \n",
    "#         Q_values_assist = self.assist_model([input_B, input_C])\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             Q_values_user = self.user_model(input_A)\n",
    "#             error = tf.multiply(self.loss_fn(Q_values_assist, Q_values_user), importance**(1-self.epsilon))\n",
    "#             loss = tf.reduce_mean(error)\n",
    "            \n",
    "#         grads = tape.gradient(loss, self.user_model.trainable_variables)\n",
    "#         self.optimizer.apply_gradients(zip(grads, self.user_model.trainable_variables))\n",
    "            \n",
    "#         with tf.GradientTape() as tape:\n",
    "#             Q_values_assist = self.assist_model([input_B, input_C])\n",
    "#             error = tf.multiply(self.loss_fn(Q_values_assist, Q_values_user), importance**(1-self.epsilon))\n",
    "#             loss = tf.reduce_mean(error)\n",
    "            \n",
    "#         grads = tape.gradient(loss, self.assist_model.trainable_variables)\n",
    "#         self.optimizer.apply_gradients(zip(grads, self.assist_model.trainable_variables))                          \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icon Locations:\n",
      "[[0.  0.8]\n",
      " [0.4 0.8]\n",
      " [0.9 0.2]\n",
      " [0.9 0.3]\n",
      " [0.3 0.6]\n",
      " [0.6 0.3]]\n",
      "Icon usage Probabilities\n",
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2)            0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           96          subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            132         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1)]          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 4)]          0           dense_4[0][0]                    \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 4)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,317\n",
      "Trainable params: 1,317\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 11, 11, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 9, 9, 2)      20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 4, 4, 2)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4, 32)        224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1056        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           lstm[0][0]                       \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 1)]          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 4)]          0           dense_6[0][0]                    \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 4)]          0           tf_op_layer_Sub_1[0][0]          \n",
      "                                                                 dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,865\n",
      "Trainable params: 11,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 11, 11, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 9, 9, 2)      20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 4, 4, 2)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4, 32)        224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2)            0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           8320        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           1056        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           96          subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           lstm[0][0]                       \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            132         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean (TensorFlowOpL [(None, 1)]          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFlowO [(None, 1)]          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 4)]          0           dense_4[0][0]                    \n",
      "                                                                 tf_op_layer_Mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_OneHot (TensorFlowO [(None, 1, 4)]       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlowOp [(None, 4)]          0           dense_6[0][0]                    \n",
      "                                                                 tf_op_layer_Mean_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_OneHot_1 (TensorFlo [(None, 1, 4)]       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 4)]          0           tf_op_layer_Sub[0][0]            \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_OneHot[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 4)]          0           tf_op_layer_Sub_1[0][0]          \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 4)]          0           tf_op_layer_OneHot_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_AddV2[0][0]          \n",
      "                                                                 tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 4)]          0           tf_op_layer_AddV2_1[0][0]        \n",
      "                                                                 tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 4)]          0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlowOp [(None, 1)]          0           tf_op_layer_AddV2_2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 13,182\n",
      "Trainable params: 13,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "steps = 4\n",
    "model = AI_Design(steps)\n",
    "env = model.env\n",
    "\n",
    "# if os.path.exists('user_model.h5'):\n",
    "#     model.user_model = tf.keras.models.load_model('user_model.h5')\n",
    "#     model.assist_model = tf.keras.models.load_model('assist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_prev_steps(prev_steps_assist, steps):\n",
    "    prev_steps_assist = [[0,0,0,0,-1,-1] for i in range(steps-1)]\n",
    "    return prev_steps_assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 101/100000 [00:08<4:05:58,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                          | 201/100000 [00:23<4:28:52,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                          | 502/100000 [01:05<3:57:23,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -30.93637521773998\n",
      "Successful runs = 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                          | 601/100000 [01:20<4:31:17,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                         | 1002/100000 [02:16<4:02:49,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.361438974570753\n",
      "Successful runs = 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                                                         | 1502/100000 [03:31<4:07:46,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.07107660014679\n",
      "Successful runs = 18.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                        | 2001/100000 [04:49<4:52:19,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.67523611664215\n",
      "Successful runs = 13.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                        | 2201/100000 [05:27<5:43:22,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▊                                                                        | 2502/100000 [06:22<4:56:43,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.827999326852513\n",
      "Successful runs = 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▏                                                                       | 3001/100000 [07:55<5:03:22,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -24.978178210777525\n",
      "Successful runs = 16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▌                                                                       | 3501/100000 [09:30<5:28:53,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.695036803678924\n",
      "Successful runs = 14.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                       | 4002/100000 [11:06<5:16:34,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.288126023338677\n",
      "Successful runs = 15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▎                                                                      | 4502/100000 [12:45<5:24:36,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.478683202647204\n",
      "Successful runs = 13.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                      | 5002/100000 [14:23<5:11:01,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -31.69103183839072\n",
      "Successful runs = 14.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████                                                                      | 5501/100000 [16:05<5:22:11,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -31.717250357031624\n",
      "Successful runs = 13.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▍                                                                     | 6001/100000 [17:47<5:11:48,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -31.640814666567234\n",
      "Successful runs = 10.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▊                                                                     | 6501/100000 [19:32<5:15:11,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.35421696855135\n",
      "Successful runs = 15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                    | 7001/100000 [21:16<5:10:07,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.017467843100906\n",
      "Successful runs = 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                    | 7101/100000 [21:38<5:53:39,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▌                                                                    | 7501/100000 [23:05<5:53:04,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -25.543622473007826\n",
      "Successful runs = 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▉                                                                    | 8002/100000 [24:53<5:32:55,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.2716462525397\n",
      "Successful runs = 17.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▎                                                                   | 8501/100000 [26:44<6:00:37,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Saved Weights\n",
      "Running reward = -23.101870708368352\n",
      "Successful runs = 21.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                   | 9001/100000 [28:34<5:34:02,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -23.09390034172622\n",
      "Successful runs = 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████                                                                   | 9501/100000 [30:28<5:58:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.524912149943397\n",
      "Successful runs = 16.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▎                                                                 | 10001/100000 [32:22<5:58:18,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.938182048528507\n",
      "Successful runs = 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▋                                                                 | 10501/100000 [34:18<5:50:02,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -26.537643095516483\n",
      "Successful runs = 17.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████                                                                 | 11002/100000 [36:16<5:27:11,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -25.51904503124619\n",
      "Successful runs = 18.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▍                                                                | 11501/100000 [38:16<6:06:46,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -25.68419810907637\n",
      "Successful runs = 19.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▍                                                                | 11601/100000 [38:41<6:14:13,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▊                                                                | 12001/100000 [40:17<6:06:03,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.34068368965187\n",
      "Successful runs = 19.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████                                                                | 12401/100000 [41:56<6:20:36,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▏                                                               | 12501/100000 [42:20<6:18:11,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -24.56568342329741\n",
      "Successful runs = 22.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▍                                                               | 13001/100000 [44:23<6:04:28,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -26.26656647476318\n",
      "Successful runs = 23.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████▊                                                               | 13501/100000 [46:28<5:52:23,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -22.620004347532525\n",
      "Successful runs = 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▏                                                              | 14001/100000 [48:34<6:28:46,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -22.229288656998367\n",
      "Successful runs = 24.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▌                                                              | 14501/100000 [50:41<6:34:50,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Saved Weights\n",
      "Running reward = -19.3019944967154\n",
      "Successful runs = 25.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▉                                                              | 15001/100000 [52:49<6:16:59,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -19.01000507369305\n",
      "Successful runs = 28.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████                                                              | 15101/100000 [53:14<6:26:30,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▎                                                             | 15501/100000 [54:59<6:31:57,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -24.69282308931102\n",
      "Successful runs = 27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▋                                                             | 16001/100000 [57:10<6:38:00,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -20.22298509929715\n",
      "Successful runs = 28.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▉                                                             | 16401/100000 [58:56<6:51:25,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████                                                             | 16501/100000 [59:23<6:32:47,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -17.684953985996287\n",
      "Successful runs = 31.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████                                                             | 16601/100000 [59:48<6:59:07,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████                                                           | 17001/100000 [1:01:35<6:13:04,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -17.646933022241488\n",
      "Successful runs = 35.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▍                                                          | 17501/100000 [1:03:50<6:04:32,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -13.933064447827489\n",
      "Successful runs = 34.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▍                                                          | 17601/100000 [1:04:16<6:46:51,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▊                                                          | 18001/100000 [1:06:05<6:31:13,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -14.928443725343898\n",
      "Successful runs = 34.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▏                                                         | 18501/100000 [1:08:23<6:36:50,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -16.193099355927956\n",
      "Successful runs = 34.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▍                                                         | 19001/100000 [1:10:41<6:49:11,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -19.05820958159213\n",
      "Successful runs = 31.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████▊                                                         | 19501/100000 [1:13:03<7:06:24,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -17.455345730421197\n",
      "Successful runs = 35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▏                                                        | 20000/100000 [1:15:25<6:27:17,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -14.973835863525938\n",
      "Successful runs = 31.6\n",
      "[3 1 3 2] [1 2 1 3]\n",
      "tf.Tensor(\n",
      "[[-0.31179044 -0.2733512  -0.3175138  -0.33816212]\n",
      " [-0.3951024  -0.3846099  -0.4139261  -0.37656763]\n",
      " [-0.36227763 -0.36240944 -0.35491338 -0.3893795 ]\n",
      " [-0.24921702 -0.23261121 -0.27240154 -0.2383579 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.6752957 -1.666479  -1.6571398 -1.6590617]\n",
      " [-1.6729501 -1.6710753 -1.6673231 -1.6799183]\n",
      " [-1.6787312 -1.6904724 -1.7058456 -1.6677287]\n",
      " [-1.7195377 -1.7132518 -1.7086098 -1.7095699]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▏                                                        | 20001/100000 [1:15:25<8:16:20,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.004641 ]\n",
      " [-2.051933 ]\n",
      " [-2.0798519]\n",
      " [-1.9819715]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████▌                                                        | 20501/100000 [1:17:48<6:12:54,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -13.849264685606043\n",
      "Successful runs = 35.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████▊                                                        | 20801/100000 [1:19:12<6:57:42,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████▉                                                        | 21001/100000 [1:20:09<5:58:22,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -12.187085597203335\n",
      "Successful runs = 44.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▎                                                       | 21501/100000 [1:22:32<6:47:09,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -9.922716960814943\n",
      "Successful runs = 44.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▌                                                       | 22001/100000 [1:24:57<6:06:08,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -13.718410566659577\n",
      "Successful runs = 36.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████▉                                                       | 22501/100000 [1:27:23<6:26:26,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -11.69119384176677\n",
      "Successful runs = 45.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▎                                                      | 23001/100000 [1:29:49<6:25:30,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -9.550758016988548\n",
      "Successful runs = 44.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████▋                                                      | 23501/100000 [1:32:18<6:56:03,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -9.396550872944477\n",
      "Successful runs = 39.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████                                                      | 24001/100000 [1:34:50<6:34:31,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -10.255139124984165\n",
      "Successful runs = 37.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▍                                                     | 24501/100000 [1:37:24<6:23:36,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -17.076302674468913\n",
      "Successful runs = 34.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▊                                                     | 25001/100000 [1:39:56<6:56:15,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -12.449740256322862\n",
      "Successful runs = 36.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████                                                     | 25501/100000 [1:42:29<6:23:41,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -8.149276353785954\n",
      "Successful runs = 42.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████▍                                                    | 26001/100000 [1:45:04<7:09:43,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -14.128490136153646\n",
      "Successful runs = 41.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████▊                                                    | 26501/100000 [1:47:42<5:51:22,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -12.24818624429817\n",
      "Successful runs = 39.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████▏                                                   | 27001/100000 [1:50:19<6:00:20,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -12.846097412838013\n",
      "Successful runs = 38.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████▌                                                   | 27501/100000 [1:53:01<7:07:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -15.327872040698725\n",
      "Successful runs = 35.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████▉                                                   | 28001/100000 [1:55:36<5:15:53,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 0.09061082395159643\n",
      "Successful runs = 51.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▏                                                  | 28401/100000 [1:57:42<7:30:09,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████▏                                                  | 28501/100000 [1:58:12<6:57:32,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -1.6089189259246384\n",
      "Successful runs = 52.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████▌                                                  | 29001/100000 [2:00:49<6:19:18,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -4.1652953408899736\n",
      "Successful runs = 53.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████▉                                                  | 29501/100000 [2:03:27<6:49:47,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 1.4594102545114658\n",
      "Successful runs = 55.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▏                                                 | 29901/100000 [2:05:31<5:50:16,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▎                                                 | 30001/100000 [2:06:04<6:28:34,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 0.7878786115394083\n",
      "Successful runs = 55.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████▋                                                 | 30501/100000 [2:08:41<5:43:49,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 1.8137664789003713\n",
      "Successful runs = 55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████                                                 | 31001/100000 [2:11:20<5:34:08,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -1.7164952536039049\n",
      "Successful runs = 54.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████                                                 | 31101/100000 [2:11:51<6:23:33,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▎                                                | 31501/100000 [2:14:01<7:06:47,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 1.543892107137797\n",
      "Successful runs = 62.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▋                                                | 32001/100000 [2:16:41<6:17:15,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 3.22170305099649\n",
      "Successful runs = 61.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████                                                | 32401/100000 [2:18:53<6:14:32,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████                                                | 32501/100000 [2:19:25<5:53:41,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 5.848697821907434\n",
      "Successful runs = 60.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████▍                                               | 33001/100000 [2:22:07<6:15:45,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 5.4291216236837005\n",
      "Successful runs = 58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████▊                                               | 33501/100000 [2:24:51<6:15:13,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Saved Weights\n",
      "Running reward = 8.645261867142933\n",
      "Successful runs = 61.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████▏                                              | 34001/100000 [2:27:34<5:23:12,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 7.211393641645805\n",
      "Successful runs = 63.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▍                                              | 34501/100000 [2:30:17<5:18:46,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 8.463158594297665\n",
      "Successful runs = 65.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▊                                              | 34901/100000 [2:32:27<5:54:54,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▊                                              | 35001/100000 [2:32:58<6:32:04,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 13.995100091903225\n",
      "Successful runs = 65.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████▏                                             | 35501/100000 [2:35:42<6:16:59,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 8.68187248572421\n",
      "Successful runs = 69.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████▌                                             | 36001/100000 [2:38:26<6:09:15,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Saved Weights\n",
      "Running reward = 12.519060308523418\n",
      "Successful runs = 69.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████▉                                             | 36501/100000 [2:41:10<6:02:35,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 10.380105004907875\n",
      "Successful runs = 66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████▎                                            | 37001/100000 [2:44:05<5:55:05,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 0.30694910565241007\n",
      "Successful runs = 55.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████▋                                            | 37501/100000 [2:47:04<6:56:04,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -2.440057187888355\n",
      "Successful runs = 51.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████▉                                            | 38001/100000 [2:49:56<5:22:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 4.601523639058476\n",
      "Successful runs = 61.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████▎                                           | 38501/100000 [2:52:47<6:40:16,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 4.077610193368068\n",
      "Successful runs = 59.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████▋                                           | 39001/100000 [2:55:39<4:51:46,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 10.542438083389838\n",
      "Successful runs = 63.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████                                           | 39501/100000 [2:58:33<7:03:52,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 9.319895482159533\n",
      "Successful runs = 66.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████▍                                          | 40001/100000 [3:01:26<6:37:46,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 4.246700636227574\n",
      "Successful runs = 66.8\n",
      "[0 3 1 1] [1 2 1 0]\n",
      "tf.Tensor(\n",
      "[[0.19016941 0.16146566 0.2222745  0.14302088]\n",
      " [0.17084843 0.15718013 0.15621622 0.17309497]\n",
      " [0.15629217 0.15832515 0.1436447  0.16280055]\n",
      " [0.18569481 0.14448832 0.14897048 0.13638486]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.16377436 0.31190655 0.14402676 0.22618774]\n",
      " [0.16811773 0.32872295 0.16141167 0.23814388]\n",
      " [0.17033651 0.31113636 0.15659991 0.23215319]\n",
      " [0.18415868 0.3451572  0.16398871 0.24619429]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.50207597]\n",
      " [0.33450663]\n",
      " [0.4694615 ]\n",
      " [0.32864702]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████▊                                          | 40501/100000 [3:04:17<5:42:10,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 10.684546580219367\n",
      "Successful runs = 70.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████                                          | 41001/100000 [3:07:13<6:42:04,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 9.139731258641667\n",
      "Successful runs = 67.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████▎                                         | 41301/100000 [3:08:57<5:34:13,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████▍                                         | 41501/100000 [3:10:07<6:50:46,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 12.361117934743062\n",
      "Successful runs = 70.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████▊                                         | 42001/100000 [3:12:59<6:02:50,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 12.173448546836504\n",
      "Successful runs = 70.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████▏                                        | 42501/100000 [3:15:55<5:34:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 13.850451716770259\n",
      "Successful runs = 71.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████▌                                        | 43001/100000 [3:18:48<6:35:32,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 12.302287146991867\n",
      "Successful runs = 73.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████▉                                        | 43501/100000 [3:21:43<6:21:41,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 12.827037582918908\n",
      "Successful runs = 73.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████▏                                       | 44001/100000 [3:24:36<5:37:17,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 17.693037433996434\n",
      "Successful runs = 74.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████▌                                       | 44501/100000 [3:27:37<5:40:09,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 8.142568610980401\n",
      "Successful runs = 69.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████▉                                       | 45001/100000 [3:30:32<5:43:22,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 14.074105586008068\n",
      "Successful runs = 74.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▎                                      | 45501/100000 [3:33:29<5:39:07,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 12.797808714064406\n",
      "Successful runs = 75.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▋                                      | 46001/100000 [3:36:23<5:01:25,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 17.586917659628238\n",
      "Successful runs = 77.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████                                      | 46501/100000 [3:39:13<4:05:07,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 16.98694718481898\n",
      "Successful runs = 78.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████████████████▎                                     | 47001/100000 [3:42:06<5:08:53,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 17.96779901517572\n",
      "Successful runs = 78.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████▋                                     | 47501/100000 [3:44:59<6:37:08,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 14.530534408949821\n",
      "Successful runs = 78.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████▉                                     | 47801/100000 [3:46:43<6:09:30,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████                                     | 48001/100000 [3:47:53<4:33:57,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 19.76459766691691\n",
      "Successful runs = 81.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████▍                                    | 48501/100000 [3:50:53<5:33:27,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 16.019264626112268\n",
      "Successful runs = 75.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████▊                                    | 49001/100000 [3:53:43<4:54:02,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 21.781619296635043\n",
      "Successful runs = 82.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████▉                                    | 49201/100000 [3:54:53<5:14:33,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████▏                                   | 49501/100000 [3:56:38<5:00:59,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 19.64720875637838\n",
      "Successful runs = 81.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████▌                                   | 50001/100000 [3:59:34<4:44:17,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 21.508852781262313\n",
      "Successful runs = 79.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████▊                                   | 50501/100000 [4:02:38<4:47:09,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 18.952182121883595\n",
      "Successful runs = 75.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████▏                                  | 51001/100000 [4:05:38<3:30:54,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 18.96288695721998\n",
      "Successful runs = 76.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████▎                                  | 51201/100000 [4:06:44<4:30:45,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▌                                  | 51501/100000 [4:08:27<4:52:18,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 25.24323861077505\n",
      "Successful runs = 88.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▉                                  | 52001/100000 [4:11:21<4:31:12,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 23.73497401554296\n",
      "Successful runs = 86.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████▎                                 | 52501/100000 [4:14:18<5:09:49,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 22.34285451145577\n",
      "Successful runs = 83.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████▋                                 | 53001/100000 [4:17:14<4:10:50,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 26.256301885691595\n",
      "Successful runs = 84.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████▉                                 | 53501/100000 [4:20:05<3:30:04,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 23.693360066257597\n",
      "Successful runs = 87.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████▏                                | 53701/100000 [4:21:13<4:28:23,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████▎                                | 54001/100000 [4:22:51<4:25:28,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 31.604691780420517\n",
      "Successful runs = 91.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████▋                                | 54501/100000 [4:25:41<4:36:02,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 20.19111490337612\n",
      "Successful runs = 88.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████                                | 55001/100000 [4:28:28<3:44:06,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 32.47474340292974\n",
      "Successful runs = 88.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████                                | 55101/100000 [4:28:59<4:12:48,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████▏                               | 55201/100000 [4:29:30<3:47:45,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Saved Weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████▍                               | 55501/100000 [4:31:06<3:31:33,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 34.03402703663692\n",
      "Successful runs = 97.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████▊                               | 56001/100000 [4:33:47<3:33:15,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 34.68403274292869\n",
      "Successful runs = 92.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████                               | 56501/100000 [4:36:25<5:05:49,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 27.59271958998323\n",
      "Successful runs = 93.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████▍                              | 57001/100000 [4:39:20<3:21:25,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 29.07936386726787\n",
      "Successful runs = 85.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████▊                              | 57501/100000 [4:42:15<3:40:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 28.005469553784813\n",
      "Successful runs = 89.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████▏                             | 58001/100000 [4:44:55<3:38:38,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 35.065602990297116\n",
      "Successful runs = 95.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████▌                             | 58501/100000 [4:47:48<3:37:47,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 25.74563659437329\n",
      "Successful runs = 90.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████▉                             | 59001/100000 [4:50:35<4:51:19,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 31.23913174791924\n",
      "Successful runs = 92.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████▏                            | 59501/100000 [4:53:32<4:29:49,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 20.464152765086055\n",
      "Successful runs = 87.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████▌                            | 60001/100000 [4:56:26<4:22:32,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 29.653254080596025\n",
      "Successful runs = 91.6\n",
      "[0 2 1 0] [1 1 1 3]\n",
      "tf.Tensor(\n",
      "[[0.7014769  0.6481849  0.6557882  0.66006714]\n",
      " [0.72440445 0.7516729  0.7598224  0.63356674]\n",
      " [0.68815404 0.73041385 0.68341345 0.7112649 ]\n",
      " [0.71967435 0.74203604 0.64176434 0.8106936 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2.912241  3.0262358 2.8865206 2.883346 ]\n",
      " [3.018256  3.1429152 2.9861982 3.0186596]\n",
      " [2.9270604 3.0302603 2.9040632 2.9112747]\n",
      " [2.994915  3.068125  3.0318718 2.9996629]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3.7277126]\n",
      " [3.9027376]\n",
      " [3.7606742]\n",
      " [3.7193372]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████▉                            | 60501/100000 [4:59:22<5:08:13,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 24.129912963782623\n",
      "Successful runs = 87.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████▎                           | 61001/100000 [5:02:13<3:38:31,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 32.335031897346326\n",
      "Successful runs = 90.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████▋                           | 61501/100000 [5:05:08<2:37:50,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 29.479424991967427\n",
      "Successful runs = 87.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████                           | 62001/100000 [5:08:01<3:12:58,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 27.75870834052706\n",
      "Successful runs = 88.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████▍                          | 62501/100000 [5:10:39<2:35:57,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 37.03836580081943\n",
      "Successful runs = 93.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████▋                          | 63001/100000 [5:13:20<5:04:09,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 30.594361158219776\n",
      "Successful runs = 95.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████                          | 63501/100000 [5:15:58<2:55:18,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 35.50860751669092\n",
      "Successful runs = 96.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████▍                         | 64001/100000 [5:18:26<3:23:54,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 39.14700033148675\n",
      "Successful runs = 99.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████▊                         | 64501/100000 [5:21:14<2:52:38,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 31.38192925414566\n",
      "Successful runs = 89.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████▏                        | 65001/100000 [5:23:51<2:56:09,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 37.5524346053749\n",
      "Successful runs = 95.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████▌                        | 65501/100000 [5:26:25<2:49:04,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 38.72605940861788\n",
      "Successful runs = 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████▊                        | 66001/100000 [5:28:52<2:31:27,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 39.476432696854346\n",
      "Successful runs = 99.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████▏                       | 66501/100000 [5:31:52<2:49:48,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 20.97606187323722\n",
      "Successful runs = 88.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████▌                       | 67001/100000 [5:35:08<4:19:31,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = 17.20985267807055\n",
      "Successful runs = 78.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████▉                       | 67501/100000 [5:39:08<4:07:10,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -2.519425741241594\n",
      "Successful runs = 55.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████▎                      | 68001/100000 [5:43:30<4:45:17,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -15.971943297794008\n",
      "Successful runs = 38.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████▋                      | 68501/100000 [5:48:05<5:08:40,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -14.391653826370264\n",
      "Successful runs = 30.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████▉                      | 69001/100000 [5:52:54<5:33:19,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.837172539179985\n",
      "Successful runs = 21.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████▎                     | 69501/100000 [5:57:47<4:50:05,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -23.80170246719706\n",
      "Successful runs = 20.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████▋                     | 70001/100000 [6:02:34<5:08:05,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -26.65445552017332\n",
      "Successful runs = 23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████                     | 70501/100000 [6:07:40<5:18:59,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.58922047608793\n",
      "Successful runs = 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████▍                    | 71001/100000 [6:12:42<5:03:18,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.62370838894922\n",
      "Successful runs = 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████▊                    | 71501/100000 [6:17:54<4:28:20,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.003491908426835\n",
      "Successful runs = 9.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████                    | 72001/100000 [6:22:54<4:59:58,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -31.091299759266494\n",
      "Successful runs = 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████▍                   | 72501/100000 [6:28:05<4:23:50,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -30.97311617488656\n",
      "Successful runs = 11.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████▊                   | 73001/100000 [6:33:19<4:48:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -33.705168368686515\n",
      "Successful runs = 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████▏                  | 73501/100000 [6:38:34<4:24:21,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -33.20994366908033\n",
      "Successful runs = 8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████▌                  | 74001/100000 [6:43:54<4:35:35,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -34.98962479549432\n",
      "Successful runs = 5.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████▉                  | 74501/100000 [6:49:18<4:52:07,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -33.803893662489116\n",
      "Successful runs = 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████▎                 | 75001/100000 [6:54:38<4:41:07,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -34.420755238059336\n",
      "Successful runs = 7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████▌                 | 75501/100000 [7:00:06<4:41:09,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.44093301148401\n",
      "Successful runs = 5.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████▉                 | 76001/100000 [7:05:36<4:30:50,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -35.0587725288503\n",
      "Successful runs = 6.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████▎                | 76501/100000 [7:11:02<3:39:32,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -23.131340192148905\n",
      "Successful runs = 13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████▋                | 77001/100000 [7:16:14<3:21:59,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.15752856319918\n",
      "Successful runs = 16.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████                | 77501/100000 [7:21:35<4:05:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.90874257847119\n",
      "Successful runs = 13.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████▍               | 78001/100000 [7:26:55<3:32:44,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.16021929041203\n",
      "Successful runs = 12.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████▋               | 78501/100000 [7:32:18<4:12:40,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -30.85845740552718\n",
      "Successful runs = 12.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████               | 79001/100000 [7:37:43<4:04:19,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -31.105851645375367\n",
      "Successful runs = 11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████▍              | 79501/100000 [7:43:09<4:07:45,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.023200019773164\n",
      "Successful runs = 11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████▊              | 80001/100000 [7:48:44<3:48:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -33.43162662356081\n",
      "Successful runs = 7.8\n",
      "[3 0 1 3] [2 1 1 2]\n",
      "tf.Tensor(\n",
      "[[-2.7576947 -2.8199055 -2.991744  -2.6297495]\n",
      " [-1.9843416 -2.0339596 -2.1781437 -1.9892555]\n",
      " [-2.1353617 -2.1280568 -2.3961046 -2.1842575]\n",
      " [-2.7576947 -2.8199055 -2.991744  -2.6297495]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-2.2977145 -2.4104044 -2.0768876 -2.2706087]\n",
      " [-1.8164057 -1.9939046 -1.673021  -1.8010006]\n",
      " [-1.9262489 -2.0618067 -1.7809944 -1.9029275]\n",
      " [-2.2977145 -2.4104044 -2.0768876 -2.2706087]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-4.7066374]\n",
      " [-3.9782462]\n",
      " [-4.189863 ]\n",
      " [-4.7066374]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████▏             | 80501/100000 [7:54:16<3:50:34,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -29.72555167337929\n",
      "Successful runs = 11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████▌             | 81001/100000 [7:59:44<3:28:16,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -28.041965960666435\n",
      "Successful runs = 12.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████▊             | 81501/100000 [8:05:15<3:46:12,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.01312420087762\n",
      "Successful runs = 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████▏            | 82001/100000 [8:10:44<2:26:24,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -26.777883516359886\n",
      "Successful runs = 14.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████▌            | 82501/100000 [8:16:26<3:32:41,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -34.11293823604026\n",
      "Successful runs = 9.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████▉            | 83001/100000 [8:22:00<3:10:59,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -27.967681674315195\n",
      "Successful runs = 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████▎           | 83501/100000 [8:27:52<2:55:16,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -34.05888175285293\n",
      "Successful runs = 6.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████▋           | 84001/100000 [8:33:38<3:14:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.13186044657302\n",
      "Successful runs = 9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████▉           | 84501/100000 [8:39:19<3:15:41,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -34.070304191068715\n",
      "Successful runs = 13.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████▎          | 85001/100000 [8:45:04<2:23:25,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -32.266667708732555\n",
      "Successful runs = 11.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████▋          | 85501/100000 [8:50:43<2:13:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward = -26.188290763868068\n",
      "Successful runs = 15.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████          | 85991/100000 [8:56:28<1:27:23,  2.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-12669be12bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mob_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_steps_assist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_assist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_steps_assist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mepisode_reward\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mreward_user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-723d56d2348b>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, ob_user, prev_steps_assist)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mtarget_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mob_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0maction_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_policy_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mob_user\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0maction_user_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-723d56d2348b>\u001b[0m in \u001b[0;36mexp_policy_user\u001b[1;34m(self, state, next_action)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnext_action\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mQ_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mQ_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_user_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3096\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3098\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_defun_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3099\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = 40\n",
    "reached = 0\n",
    "reached_history = []\n",
    "max_reached = 0\n",
    "\n",
    "running_reward = 0\n",
    "\n",
    "for epoch in tqdm(range(100000)):\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    start, dest = env.give_start_dest()\n",
    "    ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "    prev_steps_assist = []\n",
    "    prev_steps_assist = give_prev_steps(prev_steps_assist, steps)\n",
    "    step = 0\n",
    "    \n",
    "    while not done and step<max_steps:\n",
    "        ob_user, prev_steps_assist, reward_user, reward_assist, done = model.step(ob_user, prev_steps_assist)\n",
    "        episode_reward+=reward_user\n",
    "        step+=1\n",
    "        if done:\n",
    "            reached+=1\n",
    "    \n",
    "    if epoch:\n",
    "        running_reward = 0.01 * episode_reward + (1 - 0.01) * running_reward\n",
    "    else:\n",
    "        running_reward = episode_reward\n",
    "        \n",
    "    if epoch>50:\n",
    "        model.train()\n",
    "        \n",
    "        if epoch%100==0:\n",
    "            model.target_user_model.set_weights(model.user_model.get_weights())\n",
    "            model.target_assist_model.set_weights(model.assist_model.get_weights())\n",
    "            reached_history.append(reached)\n",
    "            rewards = []\n",
    "            \n",
    "            if reached>max_reached:\n",
    "                print(reached)\n",
    "                print('Saved Weights')\n",
    "                max_reached = reached\n",
    "                model.user_model.save('user_model.h5')\n",
    "                model.assist_model.save('assist_model.h5')\n",
    "                \n",
    "            reached = 0\n",
    "            \n",
    "            if epoch%500==0:\n",
    "                print(f'Running reward = {running_reward}')\n",
    "                print(f'Successful runs = {np.mean(reached_history)}')\n",
    "                reached_history = []\n",
    "                \n",
    "                if epoch%1000==0:\n",
    "                    model.epsilon-=0.01\n",
    "                    model.epsilon= max(model.epsilon, 0.1)\n",
    "                    \n",
    "                    if epoch%20000==0:\n",
    "                        model.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model.user_model = tf.keras.models.load_model('user_model.h5')\n",
    "model.assist_model = tf.keras.models.load_model('assist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1] [2 2 2 3]\n",
      "tf.Tensor(\n",
      "[[0.9516038  0.8917836  0.9332022  0.82326126]\n",
      " [0.9098215  0.9214255  0.91650915 0.79966193]\n",
      " [0.9098215  0.9214255  0.91650915 0.79966193]\n",
      " [0.8878898  0.92717445 0.88216174 0.7957046 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.2889824 4.79168   4.230976  4.238483 ]\n",
      " [4.3104734 4.805112  4.2488728 4.2613645]\n",
      " [4.252157  4.741939  4.1969833 4.202025 ]\n",
      " [4.2992435 4.8114977 4.2456346 4.2587614]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-2.9156542]\n",
      " [-2.922504 ]\n",
      " [-2.8914485]\n",
      " [-3.110583 ]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.4, 0.5, 0.7]\n",
      "[0.4, 0.5, 0.5, 0.7]\n",
      "[0.4, 0.6, 0.5, 0.7]\n",
      "[0.4, 0.7, 0.5, 0.7]\n",
      "[0.5, 0.7, 0.5, 0.7]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model.epsilon = 0\n",
    "done = False\n",
    "episode_reward = 0\n",
    "start, dest = env.give_start_dest()\n",
    "ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "prev_steps_assist = []\n",
    "prev_steps_assist = give_prev_steps(prev_steps_assist, steps)\n",
    "step = 0\n",
    "\n",
    "while not done and step<max_steps:\n",
    "    ob_user, prev_steps_assist, reward_user, reward_assist, done = model.step(ob_user, prev_steps_assist)\n",
    "    episode_reward+=reward_user\n",
    "    step+=1\n",
    "    print(ob_user)\n",
    "    \n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "reached = 0\n",
    "for i in range(1000):\n",
    "    model.epsilon = 0\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    start, dest = env.give_start_dest()\n",
    "    ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "    prev_steps_assist = []\n",
    "    prev_steps_assist = give_prev_steps(prev_steps_assist, steps)\n",
    "    step = 0\n",
    "\n",
    "    while not done and step<max_steps:\n",
    "        ob_user, prev_steps_assist, reward_user, reward_assist, done = model.step(ob_user, prev_steps_assist)\n",
    "        episode_reward+=reward_user\n",
    "        step+=1\n",
    "#         print(ob_user)\n",
    "        if done:\n",
    "            reached += 1\n",
    "#     print(done)\n",
    "\n",
    "print(reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0. ,  0. ,  1. ,  0. ,  0.2,  0.7],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.2,  0.6],\n",
       "        [ 1. ,  0. ,  0. ,  0. ,  0.2,  0.5],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.1,  0.5]],\n",
       "\n",
       "       [[ 0. ,  0. ,  1. ,  0. ,  0.7,  0.5],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.7,  0.4],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.7,  0.3],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.7,  0.2]],\n",
       "\n",
       "       [[ 0. ,  0. ,  1. ,  0. ,  0.2,  0.6],\n",
       "        [ 1. ,  0. ,  0. ,  0. ,  0.2,  0.5],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.1,  0.5],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.1,  0.4]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0. ,  0. ,  0. ,  0. , -1. , -1. ],\n",
       "        [ 0. ,  0. ,  0. ,  1. ,  0.6,  0.4],\n",
       "        [ 1. ,  0. ,  0. ,  0. ,  0.6,  0.5],\n",
       "        [ 0. ,  0. ,  0. ,  1. ,  0.5,  0.5]],\n",
       "\n",
       "       [[ 0. ,  0. ,  0. ,  0. , -1. , -1. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. , -1. , -1. ],\n",
       "        [ 0. ,  0. ,  0. ,  0. , -1. , -1. ],\n",
       "        [ 0. ,  0. ,  0. ,  1. ,  0.2,  0.4]],\n",
       "\n",
       "       [[ 0. ,  0. ,  1. ,  0. ,  0.3,  0.4],\n",
       "        [ 0. ,  1. ,  0. ,  0. ,  0.3,  0.3],\n",
       "        [ 0. ,  0. ,  1. ,  0. ,  0.4,  0.3],\n",
       "        [ 0. ,  1. ,  0. ,  0. ,  0.4,  0.2]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob_user, action_user, reward_user, next_ob_user, ob_assist, action_assist,\\\n",
    "reward_assist, next_ob_assist, done, importance, indices = model.sample_exp()\n",
    "input_C = np.vstack(tuple([model.env_cell_mapping]*128))\n",
    "ob_assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.assist_model([ob_assist, input_C]), axis = 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
