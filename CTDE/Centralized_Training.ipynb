{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Environment import Environment, make_one_hot, give_mapping\n",
    "from PrioritizedReplayBuffer import ReplayBuffer\n",
    "from Networks import UserActor, AsstActor, CentralizedCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_prev_steps(prev_steps_assist, steps):\n",
    "    prev_steps_assist = [[0,0,0,0,-1,-1] for i in range(steps-1)]\n",
    "    return prev_steps_assist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.user_actor = UserActor()\n",
    "        self.asst_actor = AsstActor()\n",
    "        self.critic = CentralizedCritic()\n",
    "        self.optimizer_actors = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "        self.optimizer_critic = tf.keras.optimizers.Adam(lr = 0.0002)\n",
    "        self.huber_loss = tf.keras.losses.Huber()\n",
    "        self.memory_len = 4\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.env = Environment()\n",
    "        self.env.cells = np.array([[0.7, 0.1], [0.1, 0.1], [0.5, 0.7], [0.6, 0.2], [0.7, 0.4], [0.2, 0.9]])\n",
    "        self.env_cell_mapping = give_mapping(self.env.cells)\n",
    "        self.env_cell_mapping = self.env_cell_mapping[np.newaxis, :, :, np.newaxis]\n",
    "        self.eps = 10e-6\n",
    "    \n",
    "    def learn(self):\n",
    "        env = self.env\n",
    "        max_steps = 200\n",
    "        running_reward = 0\n",
    "        reached = 0\n",
    "        \n",
    "        for epoch in tqdm(range(100000)):\n",
    "#             input_As = [] #Input of user agent\n",
    "#             input_Bs = [] #Input of assitant agent/output of user agent\n",
    "#             input_Cs = [] #Icon layout\n",
    "#             input_Ds = [] #Output of assitant agent\n",
    "            \n",
    "            user_action_probs_history = []\n",
    "            asst_action_probs_history = []\n",
    "            critic_value_history = []\n",
    "            rewards_history = []\n",
    "            returns = [] #Returns\n",
    "            \n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            start, dest = env.give_start_dest()\n",
    "            ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "            prev_steps_assist = []\n",
    "            prev_steps_assist = give_prev_steps(prev_steps_assist, self.memory_len)\n",
    "            step = 0\n",
    "            episode_reward = 0\n",
    "            \n",
    "            with tf.GradientTape(persistent = True) as tape:\n",
    "                while not done and step<max_steps:\n",
    "                    curr_loc = ob_user[:2]\n",
    "                    target_loc = ob_user[2:4]\n",
    "                    step+=1\n",
    "                    ob_user = np.array(ob_user)[np.newaxis]\n",
    "                    user_probs = self.user_actor.model(ob_user)\n",
    "                    user_action = np.random.choice(4, p=np.squeeze(user_probs))\n",
    "                    user_action_probs_history.append(tf.math.log(user_probs[0, user_action]))\n",
    "\n",
    "                    action_user_one_hot = make_one_hot(user_action, 4)\n",
    "\n",
    "                    ob_assist = [action_user_one_hot + curr_loc] \n",
    "                    ob_assist = prev_steps_assist + ob_assist\n",
    "                    ob_assist = np.array(ob_assist)[np.newaxis]\n",
    "                    \n",
    "                    asst_probs = self.asst_actor.model([ob_assist, self.env_cell_mapping])\n",
    "                    asst_action = np.random.choice(4, p=np.squeeze(asst_probs))\n",
    "                    asst_action_probs_history.append(tf.math.log(asst_probs[0, asst_action]))\n",
    "                    \n",
    "                    asst_output_one_hot = np.array(make_one_hot(asst_action, 4))[np.newaxis]\n",
    "                    \n",
    "                    critic_value = self.critic.model([ob_user, ob_assist, self.env_cell_mapping, asst_output_one_hot])\n",
    "                    critic_value_history.append(critic_value)\n",
    "                    \n",
    "                    new_loc, reward_user, reward_assist, done = self.env.step(user_action, asst_action + 1, target_loc, curr_loc)\n",
    "                    \n",
    "                    next_ob_user = new_loc[:]\n",
    "                    next_ob_user = next_ob_user + target_loc\n",
    "\n",
    "                    ob_user = next_ob_user\n",
    "                    prev_steps_assist = np.squeeze(ob_assist).tolist()[1:]\n",
    "                    \n",
    "                    rewards_history.append(reward_user)\n",
    "                    episode_reward+=reward_user\n",
    "                    \n",
    "                    if done:\n",
    "                        reached += 1\n",
    "\n",
    "                running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
    "\n",
    "                discounted_sum = 0\n",
    "                for r in rewards_history[::-1]:\n",
    "                    discounted_sum = r + self.gamma * discounted_sum\n",
    "                    returns.append(discounted_sum)\n",
    "                returns.reverse()\n",
    "                \n",
    "                returns = np.array(returns)\n",
    "                returns = (returns - np.mean(returns)) / (np.std(returns) + self.eps)\n",
    "                returns = returns.tolist()\n",
    "                \n",
    "                critic_losses = []\n",
    "                user_losses = []\n",
    "                asst_losses = []\n",
    "                \n",
    "                for log_prob_user, log_prob_asst, val, ret in zip(user_action_probs_history, asst_action_probs_history, critic_value_history,\\\n",
    "                                                                 returns):\n",
    "                    diff = ret - val\n",
    "                    user_losses.append(-log_prob_user*diff)\n",
    "                    asst_losses.append(-log_prob_asst*diff)\n",
    "                    critic_losses.append(self.huber_loss(tf.expand_dims(val, 0), tf.expand_dims(ret, 0)))\n",
    "\n",
    "                user_loss = sum(user_losses)\n",
    "                asst_loss = sum(asst_losses)\n",
    "                critic_loss = sum(critic_losses)\n",
    "\n",
    "            grads = tape.gradient(user_loss, self.user_actor.model.trainable_variables)\n",
    "            self.optimizer_actors.apply_gradients(zip(grads, self.user_actor.model.trainable_variables))\n",
    "\n",
    "            grads = tape.gradient(asst_loss, self.asst_actor.model.trainable_variables)\n",
    "            self.optimizer_actors.apply_gradients(zip(grads, self.asst_actor.model.trainable_variables))\n",
    "\n",
    "            grads = tape.gradient(critic_loss, self.critic.model.trainable_variables)\n",
    "            self.optimizer_critic.apply_gradients(zip(grads, self.critic.model.trainable_variables))\n",
    "            \n",
    "            if epoch%100 == 0:\n",
    "                print(running_reward)\n",
    "            \n",
    "            if epoch and epoch%100 == 0:\n",
    "                print(reached)\n",
    "                reached = 0\n",
    "                self.trial()\n",
    "                \n",
    "    def trial(self):\n",
    "        env = self.env\n",
    "        max_steps = 40\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        start, dest = env.give_start_dest()\n",
    "        ob_user = [start[0], start[1], dest[0], dest[1]]\n",
    "        prev_steps_assist = []\n",
    "        prev_steps_assist = give_prev_steps(prev_steps_assist, self.memory_len)\n",
    "        step = 0\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not done and step<max_steps:\n",
    "            curr_loc = ob_user[:2]\n",
    "            target_loc = ob_user[2:4]\n",
    "            step+=1\n",
    "            print(ob_user)\n",
    "\n",
    "            ob_user = np.array(ob_user)[np.newaxis]\n",
    "            user_probs = self.user_actor.model(ob_user)\n",
    "            user_action = np.argmax(np.squeeze(user_probs))\n",
    "\n",
    "            action_user_one_hot = make_one_hot(user_action, 4)\n",
    "\n",
    "            ob_assist = [action_user_one_hot + curr_loc] \n",
    "            ob_assist = prev_steps_assist + ob_assist\n",
    "            ob_assist = np.array(ob_assist)[np.newaxis]\n",
    "\n",
    "            asst_probs = self.asst_actor.model([ob_assist, self.env_cell_mapping])\n",
    "            asst_action = np.argmax(np.squeeze(asst_probs))\n",
    "\n",
    "            asst_output_one_hot = np.array(make_one_hot(asst_action, 4))[np.newaxis]\n",
    "\n",
    "            critic_value = self.critic.model([ob_user, ob_assist, self.env_cell_mapping, asst_output_one_hot])\n",
    "\n",
    "            new_loc, reward_user, reward_assist, done = self.env.step(user_action, asst_action + 1, target_loc, curr_loc)\n",
    "\n",
    "            next_ob_user = new_loc[:]\n",
    "            next_ob_user = next_ob_user + target_loc\n",
    "\n",
    "            ob_user = next_ob_user\n",
    "            prev_steps_assist = np.squeeze(ob_assist).tolist()[1:]\n",
    "            episode_reward+=reward_user\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 2)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2)            0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           96          subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           2112        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            260         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,468\n",
      "Trainable params: 2,468\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 11, 11, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 9, 9, 2)      20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 4, 4, 2)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4, 32)        224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           8320        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           lstm[0][0]                       \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            132         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,832\n",
      "Trainable params: 11,832\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 2)]          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 2)]          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 11, 11, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2)            0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 9, 2)      20          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           96          subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 4, 6)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 2)      0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           2112        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4, 32)        224         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            260         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           8320        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           1056        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32)           160         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100)          0           dense_9[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dense_11[0][0]                   \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           3232        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            33          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 15,513\n",
      "Trainable params: 15,513\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Icon Locations:\n",
      "[[0.3 0.2]\n",
      " [0.7 0. ]\n",
      " [0.3 0.1]\n",
      " [0.5 0.5]\n",
      " [0.8 0.4]\n",
      " [0.9 0.8]]\n",
      "Icon usage Probabilities\n",
      "[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 1/100000 [00:09<255:09:14,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 5/100000 [00:26<158:53:25,  5.72s/it]"
     ]
    }
   ],
   "source": [
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
